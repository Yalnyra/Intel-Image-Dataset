{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yalnyra/Intel-Image-Dataset/blob/main/Vinokur_Pretrained3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lvlELNLDcJ3"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3. Претренована модель (Resnet, Inceptionv4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3edAS3OVDOtN"
      },
      "outputs": [],
      "source": [
        "# Image load\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "# import torchvision\n",
        "from torchvision.transforms import v2 as transforms\n",
        "from torchvision import datasets, models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.utils import make_grid\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "# import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZxAWbz9Mx6AJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
        "URL = \"drive/MyDrive/Intel Image Classification\"\n",
        "# Альтернативний шлях, якщо працюєте з kaggle\n",
        "# URL = \"/kaggle/input/intel-image-classification\"\n",
        "folder = {\"kaggle\": 'seg_pred/seg_pred',\n",
        "          'train': 'seg_train/seg_train',\n",
        "          'test': 'seg_test/seg_test'\n",
        "          }\n",
        "BATCH_SIZE = 64\n",
        "_NUM_WORKERS = os.cpu_count() // 2\n",
        "_INPUT_SIZE = 150\n",
        "SEED = 1234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "97AtqisSx6AK"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def to_device(X, y):\n",
        "    return X.to(device), y.to(device, dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jBi2zJ5sx6AI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SeBQoTmIx6AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5652d18c-95dc-4e63-872a-882f5eaf4d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vw0XaIcIx6AK"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(seed=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CNXfAHxfKaL8"
      },
      "outputs": [],
      "source": [
        "classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DA4gX91rHjz"
      },
      "source": [
        "Імплементація зверху дуже повільна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LA0pUglsG0fV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6ef065fd-15a3-4e51-cc70-669d1adbe08d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/Intel-Image-Classification'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "URL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YYs3MOC8SaB"
      },
      "source": [
        "[Пост з stackoverlow](https://discuss.pytorch.org/t/accelerate-imagefolder-based-dataset-loading/195120/2) для пришвидшення завантаження\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EvpiyT-R8mSD"
      },
      "outputs": [],
      "source": [
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ui9OtSbu8xsC"
      },
      "outputs": [],
      "source": [
        "INPUT_SIZE = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IcsKTkTl8ZqM"
      },
      "outputs": [],
      "source": [
        "def create_hdf5_dataset(root_folder: str,\n",
        "                        hdf5_file: str,\n",
        "                        target_size: tuple[int, int] = (INPUT_SIZE, INPUT_SIZE),\n",
        "                        channels: int = 3) -> None:\n",
        "    \"\"\" Create an hdf5 database file from a folder containing images.\n",
        "    The images are resized to the target_size and stored in the hdf5 file.\n",
        "    This is useful when your dataset cannot fit in RAM and the data consits of many images\"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((150,150), interpolation=transforms.InterpolationMode.BILINEAR, max_size=None, antialias=True),\n",
        "        transforms.CenterCrop((150,150)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # check if data_dir points towards an existing directory\n",
        "    if not os.path.isdir(root_folder):\n",
        "        error_string = f\"Directory '{root_folder}' not found.\"\n",
        "        raise FileNotFoundError(error_string)\n",
        "\n",
        "    # generate dataset\n",
        "    try:\n",
        "        data = datasets.ImageFolder(root=root_folder, transform=transform)\n",
        "        # set chunk size for loading data and appending to hdf5 file\n",
        "        chunk_size = min(int(len(data) / 10), 1000)\n",
        "    except Exception as e:\n",
        "        raise e\n",
        "\n",
        "    num_images = len(data)\n",
        "\n",
        "    # open the hdf5 file\n",
        "    with h5py.File(hdf5_file, \"w\") as file:\n",
        "        # Create datasets with chunks for efficient storage\n",
        "        img_dataset = file.create_dataset(\"images\", shape=(num_images,\n",
        "                                                           channels,\n",
        "                                                           target_size[0],\n",
        "                                                           target_size[1]),\n",
        "                                          dtype=\"float32\", chunks=None)\n",
        "        lbl_dataset = file.create_dataset(\"labels\", shape=(num_images,),\n",
        "                                          dtype=\"int64\", chunks=None)\n",
        "        print(img_dataset.shape)\n",
        "        loader = DataLoader(data, batch_size=chunk_size, shuffle=False, num_workers=_NUM_WORKERS)\n",
        "\n",
        "        current_index = 0\n",
        "        # start batch processing (to avoid RAM overflow)\n",
        "        for images, labels in tqdm(loader):\n",
        "            chunk_size = images.size(0)\n",
        "\n",
        "            images = np.array(images)\n",
        "            labels = np.array(labels)\n",
        "\n",
        "            img = torch.tensor(images, dtype=torch.float32)\n",
        "            # img = torch.permute(img, (0, 2, 1, 3))\n",
        "            lbl = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "            img_dataset[current_index:current_index + chunk_size] = img\n",
        "            lbl_dataset[current_index:current_index + chunk_size] = lbl\n",
        "            print(img_dataset.shape)\n",
        "            current_index += chunk_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yRsAhd6B8R1D"
      },
      "outputs": [],
      "source": [
        "\"\"\" Custom dataset for loading images from an hdf5 file.\n",
        "    This system lazy loads the images from the hdf5 file.\"\"\"\n",
        "\n",
        "class Hdf5Dataset(Dataset):\n",
        "    def __init__(self, hdf5_file: str, transform: transforms = None) -> None:\n",
        "        self.hdf5_file = hdf5_file\n",
        "        self.transform = transform\n",
        "        self.dataset = None\n",
        "\n",
        "        with h5py.File(hdf5_file, \"r\") as file:\n",
        "            self.length = len(file[\"images\"])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.length\n",
        "        print(self.length)\n",
        "\n",
        "    def classes(self):\n",
        "      return np.unique()\n",
        "\n",
        "    def __getitem__(self, idx) -> tuple[torch.Tensor, int]:\n",
        "        \"\"\" Returns a tuple of image and label.\"\"\"\n",
        "        if self.dataset is None:\n",
        "            self.dataset = h5py.File(self.hdf5_file, mode=\"r\", swmr=True)\n",
        "\n",
        "        image = self.dataset[\"images\"][idx]\n",
        "        label = self.dataset[\"labels\"][idx]\n",
        "        # assert dataset is not None\n",
        "        image = np.permute_dims(image, (2,1,0))\n",
        "        # print(image)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K7LEC_E-pYMP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Args:\n",
        "    root_dir (string): Directory with all the images.\n",
        "    transform (callable, optional): Optional transform to be applied on a sample.\n",
        "\"\"\"\n",
        "\n",
        "train_dir = os.path.join(URL, folder['train'])\n",
        "test_dir  = os.path.join(URL, folder['test'])\n",
        "train_hdf5 = os.path.join(train_dir,'train.hdf5')\n",
        "test_hdf5 = os.path.join(test_dir,'test.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m9V7SrifLbwp",
        "outputId": "ae591ef2-642c-459f-92bc-1a58d50d85ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/Intel-Image-Classification/seg_train/seg_train/train.hdf5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "train_hdf5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a_kOg4w-3N-"
      },
      "source": [
        "Експортуємо дані у ту саму папку один раз, але у єдиному файлі .hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "_F4ewtdt-U-x",
        "outputId": "4602d741-efcf-4baa-f5e0-ea1a21b6e7b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Directory 'drive/MyDrive/Intel-Image-Classification/seg_train/seg_train' not found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f9f2c6d5b260>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_hdf5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mcreate_hdf5_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hdf5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_hdf5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcreate_hdf5_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_hdf5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-845c78e736b2>\u001b[0m in \u001b[0;36mcreate_hdf5_dataset\u001b[0;34m(root_folder, hdf5_file, target_size, channels)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0merror_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Directory '{root_folder}' not found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# generate dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Directory 'drive/MyDrive/Intel-Image-Classification/seg_train/seg_train' not found."
          ]
        }
      ],
      "source": [
        "if not os.path.isfile(train_hdf5):\n",
        "  create_hdf5_dataset(train_dir, train_hdf5)\n",
        "if not os.path.isfile(test_hdf5):\n",
        "  create_hdf5_dataset(test_dir, test_hdf5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq3H0jKBAAus"
      },
      "outputs": [],
      "source": [
        "# # Create the dataset\n",
        "# dataset = Hdf5Dataset(train_hdf5, transform=transform)\n",
        "\n",
        "# # Access an image tensor and its label\n",
        "# image_tensor, label = dataset[0]\n",
        "# print(image_tensor.shape, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz_M6_hYNN_t"
      },
      "outputs": [],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymc7Lorgx6AP"
      },
      "outputs": [],
      "source": [
        "class WrappedDataLoader:\n",
        "    def __init__(self, loader, func):\n",
        "        self.loader = loader\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.loader)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in iter(self.loader):\n",
        "            yield self.func(*batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzpqqSLRx6AQ"
      },
      "outputs": [],
      "source": [
        "affine_transforms = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees=15, translate=(0.05, 0.15), scale=(0.85, 1.15), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "    # transforms.RandomResizedCrop(size=(150, 150), scale=(0.15, 1), ratio=(1,1), antialias=True),\n",
        "    # transforms.RandomHorizontalFlip(p=0.),\n",
        "])\n",
        "\n",
        "augmentations = transforms.Compose([\n",
        "    transforms.GaussianNoise(sigma=0.1),\n",
        "    # transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.0)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvU-Ja04x6AP"
      },
      "outputs": [],
      "source": [
        "color_transforms = transforms.Compose([\n",
        "    # transforms.Normalize(features_mean, features_std),\n",
        "    transforms.ColorJitter(brightness=0.5, contrast=0.1, saturation=0.01),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz0ATOvWx6AQ"
      },
      "outputs": [],
      "source": [
        "repeats = 50\n",
        "features_size = BATCH_SIZE * repeats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtlAbn3mx6AQ"
      },
      "outputs": [],
      "source": [
        "# features_mean = torch.zeros(1)\n",
        "# features_squared_mean = torch.zeros(1)\n",
        "# # Only use a few batches\n",
        "# for item, label in data_train:\n",
        "#     item = test_transforms(item)\n",
        "#     features_mean += torch.mean(item)\n",
        "#     features_squared_mean += torch.mean(item ** 2)\n",
        "#     print(repeats)\n",
        "#     repeats -= 1\n",
        "#     if repeats <= 0:\n",
        "#       break\n",
        "\n",
        "# features_mean /= features_size\n",
        "# features_squared_mean /= features_size\n",
        "\n",
        "# features_std = torch.sqrt(features_squared_mean - features_mean ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIBxEsMvxUMJ"
      },
      "outputs": [],
      "source": [
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((150,150), interpolation=transforms.InterpolationMode.BILINEAR, max_size=None, antialias=True),\n",
        "    transforms.CenterCrop((150,150)),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4vKbo463CVM"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    # transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Resize((150,150), interpolation=transforms.InterpolationMode.BILINEAR, max_size=None, antialias=True),\n",
        "    # transforms.CenterCrop((150,150)),\n",
        "  #   transforms.RandomApply([\n",
        "  #   transforms.RandomChoice([\n",
        "    affine_transforms,\n",
        "    # augmentations,\n",
        "  #       # color_transforms,\n",
        "  #   ],)\n",
        "  # ], p=0.2),\n",
        "  transforms.RandomGrayscale(p=0.2),\n",
        "  # transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205)),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-4rP3JEN_-x"
      },
      "outputs": [],
      "source": [
        "heavy_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(size=(150 , 150)) ,\n",
        "    transforms.RandomCrop(size=(150,150)),\n",
        "    # transforms.ColorJitter(0.4,0.5,0.5,0.2),\n",
        "    transforms.GaussianNoise(sigma=0.1),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=15, translate=(0.05, 0.15), scale=(0.85, 1.15), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    # transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4dw1s4Ex6AT"
      },
      "outputs": [],
      "source": [
        "model_path = lambda name: f\"{URL}/{name}.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjkWYam9x6AT"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(model_path('')):\n",
        "      os.makedirs(model_path(''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqf725t6x6AR"
      },
      "outputs": [],
      "source": [
        "def loss(model, loss_func, X, y, optimizer=None):\n",
        "    loss_ = loss_func(model(X), y)\n",
        "    if optimizer is not None:\n",
        "      loss_.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    return loss_.item(), len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IjSjzVQx6AR"
      },
      "outputs": [],
      "source": [
        "def validate(model, loss_func, X, y):\n",
        "    output = model(X)\n",
        "    loss_ = loss_func(output, y)\n",
        "    pred = torch.argmax(output, dim=1)\n",
        "    correct = pred == y.view(*pred.shape)\n",
        "\n",
        "    return loss_.item(), torch.sum(correct).item(), len(X), pred, y.view(*pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb72pavIdQZh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "os2YRvL7x6AR"
      },
      "outputs": [],
      "source": [
        "def fit(epochs, model, loss_func, optimizer, train_loader, heavy_loader, valid_loader, lr_scheduler=None, patience=10):\n",
        "    graphic_losses = []\n",
        "\n",
        "    wait = 0\n",
        "    valid_loss_min = np.inf\n",
        "    step = 0\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        step = epoch\n",
        "        fraction = step / epochs\n",
        "        # Change the transforms based on epochs\n",
        "        # train_loader = valid_loader if fraction >= 0.8 else train_transforms\n",
        "        # train_loader = heavy_loader if fraction >= 0.4 and fraction <= 0.7 else train_loader\n",
        "        model.train()\n",
        "\n",
        "        losses = []\n",
        "\n",
        "        for X, y  in train_loader:\n",
        "          # print(X.shape)\n",
        "          losses.append(loss(model, loss_func, X, y, optimizer))\n",
        "\n",
        "        losses, nums = zip(*losses)\n",
        "        train_loss = sum(np.multiply(losses, nums)) / sum(nums)\n",
        "\n",
        "        model.eval()\n",
        "        # valid_loader.dataset.transform = test_transforms\n",
        "        with torch.no_grad():\n",
        "\n",
        "            losses = []\n",
        "            for X, y in valid_loader:\n",
        "              losses.append(validate(model, loss_func, X, y))\n",
        "\n",
        "\n",
        "            losses, corrects, nums, predicted, target = zip(*losses)\n",
        "            target = torch.cat([*target], dim=0).cpu()\n",
        "            predicted = torch.cat([*predicted],dim=0).cpu()\n",
        "            valid_loss = sum(np.multiply(losses, nums)) / sum(nums)\n",
        "            valid_accuracy = sum(corrects) / sum(nums) * 100\n",
        "            # Changed from total class per-point  to average weighted\n",
        "            valid_precision = precision_score(target, predicted, average='weighted')\n",
        "            valid_recall = recall_score(target, predicted,  average='weighted')\n",
        "            valid_f1 = f1_score(target, predicted,  average='weighted')\n",
        "\n",
        "            # reduce lr based on val loss\n",
        "            if lr_scheduler is not None:\n",
        "              lr_scheduler.step(valid_loss)\n",
        "\n",
        "            print(f\"\\nepoch: {epoch+1:3}, loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, valid accuracy: {valid_accuracy:.3f}, valid f1: {valid_f1:.3f}%\")\n",
        "\n",
        "            graphic_losses.append((train_loss, valid_loss, valid_accuracy, valid_precision, valid_recall, valid_f1))\n",
        "            # Save model if validation loss has decreased\n",
        "            if valid_loss <= valid_loss_min:\n",
        "                print(f\"Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model...\")\n",
        "                torch.save(model.state_dict(), 'model.pt')\n",
        "                valid_loss_min = valid_loss\n",
        "                wait = 0\n",
        "            # Early stopping\n",
        "            else:\n",
        "                wait += 1\n",
        "                # if wait >= patience:\n",
        "                #     print(f\"Terminated Training for Early Stopping at Epoch {epoch+1}\")\n",
        "                #     return graphic_losses, step\n",
        "\n",
        "    return graphic_losses, step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVKAREr3x6AR"
      },
      "source": [
        "### Тестування моделі\n",
        "\n",
        "- На додачу до простого Accuracy, потрібно знайти\n",
        "Precision\n",
        "$TP \\div (TP+FP)$\n",
        "\n",
        "Recall\n",
        "$TN \\div (TN+FN)$\n",
        "\n",
        "F1 $\\frac{1}{\\frac{1}{Precision}+\\frac{1}{Recall}} $\n",
        "\n",
        "Матрицю зкуйовдженості"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKodaUqKx6AR"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loss_func, loader):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        validated_batches = []\n",
        "\n",
        "        for X, y in loader:\n",
        "          validated_batches.append(validate(model, loss_func, X, y))\n",
        "\n",
        "        losses, corrects, nums, predicted, target = zip(*validated_batches)\n",
        "        target = torch.cat([*target], dim=0).cpu()\n",
        "        predicted = torch.cat([*predicted],dim=0).cpu()\n",
        "        cm = ConfusionMatrixDisplay.from_predictions(target, predicted)\n",
        "        plt.show()\n",
        "        test_loss = sum(np.multiply(losses, nums)) / sum(nums)\n",
        "        test_accuracy = sum(corrects) / sum(nums) * 100\n",
        "        test_precision = precision_score(target, predicted,  average='micro')\n",
        "        test_recall = recall_score(target, predicted,  average='micro')\n",
        "        test_f1 = f1_score(target, predicted,  average='micro')\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Test loss: {test_loss:.5f}\\t\",\n",
        "          f\"Test accuracy: {test_accuracy:.3f}%\",\n",
        "          f\"Test precision: {test_precision:.3f}\",\n",
        "          f\"Test recall: {test_recall:.3f}\"\n",
        "          f\"Test f1: {test_f1:.3f}\")\n",
        "    return test_loss, test_accuracy, test_precision, test_recall, test_f1, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qBBdqpbx6AS"
      },
      "outputs": [],
      "source": [
        "def training_plots(losses_arr):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot([x[2] for x in losses_arr])\n",
        "    plt.ylabel('Accuracy in %')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xticks([x + 1 for x in range(len(losses_arr)) if x % 2 == 1])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot([x[3] for x in losses_arr])\n",
        "    plt.ylabel('Precision')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xticks([x + 1 for x in range(len(losses_arr)) if x % 2 == 1])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot([x[4] for x in losses_arr])\n",
        "    plt.ylabel('Recall')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xticks([x + 1 for x in range(len(losses_arr)) if x % 2 == 1])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot([x[5] for x in losses_arr])\n",
        "    plt.ylabel('F1')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xticks([x + 1 for x in range(len(losses_arr)) if x % 2 == 1])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot([x[0] for x in losses_arr], label='train loss')\n",
        "    plt.plot([x[1] for x in losses_arr], label='validation loss')\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.ylabel('Losses')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xticks([x + 1 for x in range(len(losses_arr)) if x % 2 == 1])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPw4yIi5lzz7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td3jLWopx6AT"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, n_epochs, batch_size, lr_scheduler=None, saving_model_path=None, wb = False):\n",
        "\n",
        "    # data_train = ImageDataset(URL, True, train_transforms\n",
        "\n",
        "    # data_test = ImageDataset(URL, test_transforms)\n",
        "\n",
        "    # data_train = datasets.ImageFolder(train_dir, train_transforms)\n",
        "    # data_test = datasets.ImageFolder(test_dir, test_transforms)\n",
        "    # Deterministic split to apply transforms\n",
        "    gen = torch.Generator().manual_seed(42)\n",
        "    data_train = Hdf5Dataset(train_hdf5, transform=train_transforms)\n",
        "    data_heavy = Hdf5Dataset(train_hdf5, transform=heavy_transforms)\n",
        "    data_valid = Hdf5Dataset(train_hdf5, transform=test_transforms)\n",
        "    # Fix indices\n",
        "    # num_train = len(data_train)\n",
        "    # indices = list(range(num_train))\n",
        "    # train_indices, val_indices = train_test_split(indices, test_size=0.2)\n",
        "    data_train, data_valid = random_split(data_train, lengths=[0.8, 0.2], generator=gen)\n",
        "    # _, data_valid = random_split(data_train, lengths=[0.8, 0.2], generator=gen)\n",
        "    data_heavy, _ = random_split(data_heavy, lengths=[0.8, 0.2], generator=gen)\n",
        "    # data_train = torch.utils.data.Subset(data_train, train_indices)\n",
        "    # data_heavy = torch.utils.data.Subset(data_heavy, train_indices)\n",
        "\n",
        "    # data_valid = torch.utils.data.Subset(data_train, val_indices)\n",
        "    # data_train.transform = test_transforms\n",
        "\n",
        "    data_test = Hdf5Dataset(test_hdf5, transform=test_transforms)\n",
        "\n",
        "    # print(data_train.transform)\n",
        "    # data_train, data_valid = random_split(data_train, lengths=[0.8, 0.2])\n",
        "    # data_train.dataset.transform = test_transforms\n",
        "\n",
        "\n",
        "    loader_train = WrappedDataLoader(DataLoader(data_train, batch_size=batch_size, shuffle=True), to_device)\n",
        "    loader_heavy = WrappedDataLoader(DataLoader(data_heavy, batch_size=batch_size, shuffle=True), to_device)\n",
        "    loader_eval = WrappedDataLoader(DataLoader(data_valid, batch_size=batch_size, shuffle=False), to_device)\n",
        "    loader_test = WrappedDataLoader(DataLoader(data_test, batch_size=batch_size, shuffle=False), to_device)\n",
        "\n",
        "    print('\\nFitting nn model')\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_losses, final_step = fit(n_epochs, model, criterion, optimizer, loader_train, loader_heavy, loader_eval, lr_scheduler)\n",
        "    print(f'length array:', len(train_losses))\n",
        "    print(f'Fit time: {time.time() - start_time} s')\n",
        "    if wb:\n",
        "        wandb.log({\"train/duration\": time.time() - start_time})\n",
        "    check_point = torch.load('model.pt', map_location=device)\n",
        "    model.load_state_dict(check_point)\n",
        "\n",
        "    eval_losses = evaluate(model, criterion, loader_test)\n",
        "\n",
        "    if saving_model_path is not None:\n",
        "        print('Saving model')\n",
        "        # create 'dynamic' dir, if it does not exist\n",
        "        if not os.path.exists(model_path('')):\n",
        "          os.makedirs(model_path(''))\n",
        "        torch.save(model.state_dict(), model_path(saving_model_path))\n",
        "        if wb:\n",
        "            wandb.log_model(path=model_path(saving_model_path),name=saving_model_path)\n",
        "            for i in range(final_step):\n",
        "                train_loss, v_loss, v_acc, v_prec, v_recall, v_f1 = train_losses[i]\n",
        "                wb_dict = {\n",
        "                    \"train/loss\": train_loss,\n",
        "                    \"valid/loss\": v_loss,\n",
        "                    \"valid/accuracy\": v_acc,\n",
        "                    \"valid/precision\": v_prec,\n",
        "                    \"valid/recall\": v_recall,\n",
        "                    \"valid/f1\": v_f1,\n",
        "                           }\n",
        "                wandb.log(wb_dict, step=i)\n",
        "            test_loss, t_acc, t_prec, t_recall, t_f1, fig = eval_losses\n",
        "            wandb.log({\"test/loss\": test_loss,\n",
        "                    \"test/accuracy\": t_acc,\n",
        "                    \"test/precision\": t_prec,\n",
        "                    \"test/recall\": t_recall,\n",
        "                    \"test/f1\": t_f1}, step=final_step+1)\n",
        "            wandb.log({\"fig\":wandb.Image(fig.confusion_matrix)})\n",
        "\n",
        "    training_plots(train_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApM7VHARx6AU"
      },
      "outputs": [],
      "source": [
        "# class_weights = torch.tensor(calculate_class_weights(y_train), dtype=torch.float, device=device)\n",
        "n_epochs = 20\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSf6pwhgEJHX"
      },
      "source": [
        "Backbone Inception-v4 буде завантажено із huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2dOx1D7ESJ5"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfa1HXT_Aeq6"
      },
      "outputs": [],
      "source": [
        "pretrained = timm.create_model('inception_v4', pretrained=True)\n",
        "# num_features = pretrained.last_linear.in_features\n",
        "# pretrained.last_linear = nn.Linear(num_features, len(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFGpomGKFFG9"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "# Завантажуємо модель ResNet18 (навчена на ImageNet)\n",
        "pretrained = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "num_features = pretrained.fc.in_features\n",
        "pretrained.fc = nn.Linear(num_features, 256)\n",
        "print(num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0EGXLnDJ-IL"
      },
      "outputs": [],
      "source": [
        "for name, param in pretrained.named_parameters():\n",
        "    print(name)\n",
        "    if 'bn' in name:\n",
        "      print('no grad for:', name)\n",
        "      param.requires_grad = False\n",
        "\n",
        "# Модифікуємо останній шар (6 класів)\n",
        "\n",
        "\n",
        "# Переносимо модель на пристрій\n",
        "pretrained = pretrained.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyeuIZzyFLAB"
      },
      "outputs": [],
      "source": [
        "summary(pretrained, input_size=(3, INPUT_SIZE, INPUT_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Підморожена мережа з мінімальним learning ratr"
      ],
      "metadata": {
        "id": "GJaybDzrjGVp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "judlIJRlEpVc"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FCNInception(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        # for param in pretrained.parameters() if param:\n",
        "        #     param.requires_grad = False\n",
        "\n",
        "        # Модифікуємо останній шар (6 класів)\n",
        "        num_features = pretrained.fc.out_features\n",
        "        # pretrained.fc = nn.Linear(num_features, len(classes))\n",
        "        # self.fc1 = nn.Linear(1000, 512) # 32 * 64 # 5400\n",
        "        # self.backbone.fc = nn.Linear(num_features, len(classes))\n",
        "        self.fc2 = nn.Linear(num_features, 256)\n",
        "        self.fc3 = nn.Linear(256, len(classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "      # with torch.no_grad():\n",
        "      # x = self.backbone(x)\n",
        "      features = F.relu(self.backbone(x))\n",
        "      # x = F.relu(self.fc3(features))\n",
        "      # x = F.relu(self.fc3(x))\n",
        "      x = self.fc3(features)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ihJXyA4K0zo"
      },
      "outputs": [],
      "source": [
        "summary(model, input_size=(3, INPUT_SIZE, INPUT_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSWAsRqBx6AU"
      },
      "outputs": [],
      "source": [
        "model = FCNInception(pretrained).to(device)\n",
        "# criterion = nn.CrossEntropyLoss(class_weights)\n",
        "# criterion = nn.\n",
        "\n",
        "head = [p for name, p in model.named_parameters() if 'fc' in name]\n",
        "others = [p for name, p in model.named_parameters() if 'fc' not in name]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam([{'params': others, 'lr':5e-6}\n",
        "    ,{'params': head},], lr=0.0009, weight_decay=1e-3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exl4eHi705jt"
      },
      "outputs": [],
      "source": [
        "summary(model, input_size=(3, INPUT_SIZE, INPUT_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e-oPUBGa9Pk"
      },
      "outputs": [],
      "source": [
        "lr_sch = lr_scheduler.StepLR(optimizer, 30, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIpHFJXxa7e6"
      },
      "outputs": [],
      "source": [
        "lr_sch = lr_scheduler.ReduceLROnPlateau(optimizer, patience=10,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXrweFBmHyvg"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNgdJkMubzp6"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKa12sHoLd97"
      },
      "outputs": [],
      "source": [
        "n_epochs = 20\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC9-IoJE1MIy"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlNLoTOYx6AV"
      },
      "outputs": [],
      "source": [
        "with wandb.init(\n",
        "        settings=wandb.Settings(start_method=\"thread\"),\n",
        "        project=\"Kaggle-Intel-Image\",\n",
        "        name='part_frozen_resnet',\n",
        "        group='Backbone',\n",
        "        config={\"epochs\":n_epochs, \"batch\": BATCH_SIZE, \"transforms\": train_transforms},\n",
        "        sync_tensorboard=False,\n",
        "        resume=\"allow\",\n",
        "    ):\n",
        "\n",
        "  train(model, criterion, optimizer, n_epochs, BATCH_SIZE, lr_scheduler=lr_sch, saving_model_path='part_frozen_resnet', wb=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSPxkWwwx6AX"
      },
      "source": [
        "# Результати за посиланням на [wandb](https://wandb.ai/paradoxv15/Kaggle-Intel-Image/reports/Model-tuning-for-Intel-Image-classifier--VmlldzoxMTgxOTgwMA)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiCC4FAsx6Aj"
      },
      "outputs": [],
      "source": [
        "def validate_examples(model, loss_func, X, y):\n",
        "    output = model(X)\n",
        "    pred = torch.argmax(output, dim=1)\n",
        "    correct = pred == y.view(*pred.shape)\n",
        "\n",
        "    return X, pred, y.view(*pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA133B5Sx6Aj"
      },
      "outputs": [],
      "source": [
        "def draw_predicted_examples(image_array, grid_x, grid_y, title):\n",
        "    fig = plt.figure(figsize=(grid_x,grid_y))\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "\n",
        "    for i in range(1,grid_y*grid_x+1):\n",
        "        index = random.randint(0, len(image_array)-1)\n",
        "        image = image_array[index]\n",
        "        plt.axis('off')\n",
        "        plt.subplot(grid_y,grid_x,i)\n",
        "        plt.imshow(np.transpose(image.numpy(), (1, 2, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDp2IxGpoVyj"
      },
      "outputs": [],
      "source": [
        "# Функція для денормалізації зображення\n",
        "def denormalize_image(tensor, mean=0.5, std=0.5):\n",
        "    # tensor має форму (channels, height, width); повертає зображення у форматі HxWxC\n",
        "    img = tensor.cpu().numpy().transpose((1, 2, 0))\n",
        "    img = std * img + mean\n",
        "    return np.clip(img, 0, 1)\n",
        "\n",
        "\n",
        "# Функція для відображення зображень з прогнозами (оновлено)\n",
        "def show_predictions(model, dataloader, class_names, device, num_images=8):\n",
        "    \"\"\"\n",
        "    Відображає приклади зображень з прогнозами моделі.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            preds = preds.cpu()\n",
        "            labels = labels.cpu()\n",
        "            for j in range(inputs.size(0)):\n",
        "                true_label = labels[j].item()\n",
        "                pred_label = preds[j].item()\n",
        "                if images_so_far >= num_images:\n",
        "                    return\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(2, num_images // 2, images_so_far)\n",
        "                ax.axis(\"off\")\n",
        "                status = \"✓\" if preds[j] == labels[j] else \"✗\"\n",
        "                ax.set_title(\n",
        "                    f\"{status} Predicted: {class_names[pred_label]}\\nTarget: {class_names[true_label]}\",\n",
        "                    color=\"green\" if true_label == pred_label else \"red\",\n",
        "                    fontsize=10,\n",
        "                )\n",
        "                # Використовуємо утиліту для денормалізації\n",
        "                img = denormalize_image(inputs[j])\n",
        "                plt.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Функція для відображення лише помилкових прогнозів (оновлено)\n",
        "def show_misclassifications(model, dataloader, class_names, device, max_per_class=5):\n",
        "    \"\"\"\n",
        "    Відображає приклади помилково класифікованих зображень для кожного класу.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    misclassified = {i: [] for i in range(len(class_names))}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size(0)):\n",
        "                true_label = labels[j].item()\n",
        "                pred_label = preds[j].item()\n",
        "                if (\n",
        "                    true_label != pred_label\n",
        "                    and len(misclassified[true_label]) < max_per_class\n",
        "                ):\n",
        "                    img = denormalize_image(inputs[j])\n",
        "                    misclassified[true_label].append((img, pred_label))\n",
        "\n",
        "    for class_idx, examples in misclassified.items():\n",
        "        if not examples:\n",
        "            continue\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        plt.suptitle(\n",
        "            f\"Misclassified as '{class_names[class_idx]}'\",\n",
        "            fontsize=14,\n",
        "        )\n",
        "        for i, (img, pred_label) in enumerate(examples):\n",
        "            plt.subplot(1, len(examples), i + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.title(\n",
        "                f\"Target: {class_names[class_idx]}\\Predicted: {class_names[pred_label]}\",\n",
        "                color=\"red\",\n",
        "            )\n",
        "            plt.axis(\"off\")\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3twW62ICr89N"
      },
      "outputs": [],
      "source": [
        "data_train = Hdf5Dataset(train_hdf5, transform=train_transforms)\n",
        "\n",
        "data_test = Hdf5Dataset(test_hdf5, transform=test_transforms)\n",
        "\n",
        "data_train, data_valid = random_split(data_train, lengths=[0.8, 0.2])\n",
        "\n",
        "loader_train = WrappedDataLoader(DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True), to_device)\n",
        "loader_eval = WrappedDataLoader(DataLoader(data_valid, batch_size=BATCH_SIZE, shuffle=False), to_device)\n",
        "loader_test = WrappedDataLoader(DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=False), to_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EnzzLOEVO38"
      },
      "outputs": [],
      "source": [
        "dataset = ImageDataset(URL, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8DLyYo5L8Ub"
      },
      "outputs": [],
      "source": [
        "classes = dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlaAd4RAoGrx"
      },
      "outputs": [],
      "source": [
        "# Показ прикладів прогнозів на валідаційному наборі\n",
        "show_predictions(model, loader_test, classes, device)\n",
        "\n",
        "# Показ прикладів ПОМИЛКОВИХ прогнозів для кожного класу\n",
        "print(\"\\nПриклади помилкових класифікацій CNN моделі:\")\n",
        "show_misclassifications(model, loader_test, classes, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}